# -*- coding: utf-8 -*-
"""Crop_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18RwZlAu6LiMqmO_EcMkfovIsWYeajQhD
"""

pip install torchinfo

import os
import random
from shutil import copy2
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchinfo import summary
from torchvision import datasets, models, transforms
from tqdm.notebook import tqdm

torch.backends.cudnn.deterministic = True

if torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"
print(f"Using {device} device.")

from google.colab import drive
drive.mount('/content/drive')

data_dir = os.path.join("/content/drive/MyDrive/Colab Notebooks/DeepLeanrning/Agriculture_project/", "Agricultural-crops")

print("Data Directory:", data_dir)

classes = os.listdir(data_dir)
print("Classes:", classes)

class ConvertToRGB(object):
  def __call__(self, image):
    if image.mode != "RGB":
      image = image.convert(mode="RGB")
    return image

transform = transforms.Compose([
    ConvertToRGB(),
    transforms.Resize(size=(380, 380)),
    transforms.ToTensor()
])

dataset = datasets.ImageFolder(root=data_dir, transform=transform)

data_loader = DataLoader(dataset, batch_size=32)

def get_mean_std(loader):
  channels_sum, channels_squared_sum, num_batches = 0,0,0
  for data, _ in tqdm(loader):
    channels_sum += torch.mean(data, dim=[0,2,3])
    channels_squared_sum += torch.mean(data**2, dim=[0,2,3])
    num_batches +=1
    mean = channels_sum/num_batches
    std = (channels_squared_sum/num_batches - mean**2)**0.5
  return mean, std

mean, std = get_mean_std(data_loader)
print(mean, std)

#import shutil
#shutil.rmtree("/content/drive/MyDrive/Colab Notebooks/DeepLeanrning/Agriculture_project/undersampled")

transform_norm = transforms.Compose([
    ConvertToRGB(),
    transforms.Resize(size=(380, 380)),
    transforms.ToTensor(),
    transforms.Normalize(mean=mean, std=std)
])

norm_dataset = datasets.ImageFolder(root=data_dir, transform=transform_norm)

norm_dataloader = DataLoader(norm_dataset, batch_size=32)

new_mean, new_std = get_mean_std(norm_dataloader)

print(new_mean, new_std)

g = torch.Generator()
g.manual_seed(42)

train_dataset, val_dataset = random_split(norm_dataset, (0.8, 0.2), generator=g)

print("Length of training dataset:", len(train_dataset))
print("Length of validation dataset:", len(val_dataset))

percent_train = np.round(100 * len(train_dataset) / len(norm_dataset), 2)
percent_val = np.round(100 * len(val_dataset) / len(norm_dataset), 2)

print(f"Train data is {percent_train}% of full data")
print(f"Validation data is {percent_val}% of full data")

from collections import Counter
import pandas as pd
def class_counts(dataset):
    c = Counter(x[1] for x in tqdm(dataset))
    try:
        class_to_index = dataset.class_to_idx
    except AttributeError:
        class_to_index = dataset.dataset.class_to_idx
    return pd.Series({cat: c[idx] for cat, idx in class_to_index.items()})

train_counts = class_counts(train_dataset)
val_counts = class_counts(val_dataset)

plt.figure(figsize=(15,8))
train_counts.sort_values().plot(kind="bar");

plt.figure(figsize=(15,8))
val_counts.sort_values().plot(kind="bar");

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

test_batch = next(iter(train_loader))[0]
batch_shape = test_batch.shape

print(f"Batch shape: {batch_shape}")

model = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.DEFAULT)

summary(model, input_size=batch_shape)

for params in model.parameters():
  params.requires_grad =False

model.to(device)

list(model.named_modules())[-1]

model.classifier[1].in_features

modified_model = nn.Sequential(
    nn.Linear(in_features=model.classifier[1].in_features, out_features=500),
    nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(in_features=500, out_features=len(norm_dataset.classes))
)

model.classifier = modified_model
print(model)

model.to(device)

def train_epoch(model, optimizer, loss_fn, data_loader, device="cpu"):
    training_loss = 0.0
    model.train()

    # Iterate over all batches in the training set to complete one epoch
    for inputs, targets in tqdm(data_loader, desc="Training", leave=False):
        optimizer.zero_grad()
        inputs = inputs.to(device)
        targets = targets.to(device)

        output = model(inputs)
        loss = loss_fn(output, targets)

        loss.backward()
        optimizer.step()
        training_loss += loss.data.item() * inputs.size(0)

    return training_loss / len(data_loader.dataset)

def score(model, data_loader, loss_fn, device="cpu"):
    total_loss = 0
    total_correct = 0

    model.eval()
    with torch.no_grad():
        for inputs, targets in tqdm(data_loader, desc="Scoring", leave=False):
            inputs = inputs.to(device)
            output = model(inputs)

            targets = targets.to(device)
            loss = loss_fn(output, targets)
            total_loss += loss.data.item() * inputs.size(0)

            correct = torch.eq(torch.argmax(output, dim=1), targets)
            total_correct += torch.sum(correct).item()

    n_observations = data_loader.batch_size * len(data_loader)
    average_loss = total_loss / n_observations
    accuracy = total_correct / n_observations
    return average_loss, accuracy

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)

from torch.optim.lr_scheduler import StepLR
step_size = 4
gamma = 0.2

scheduler = StepLR(
    optimizer,
    step_size=step_size,
    gamma=gamma,
)

def early_stopping(validation_loss, best_val_loss, counter):
    """Function that implements Early Stopping"""

    stop = False

    if validation_loss < best_val_loss:
        counter = 0
    else:
        counter += 1


    if counter>=5:
        stop =True

    return counter, stop

def checkpointing(validation_loss, best_val_loss, model, optimizer, save_path):

    if validation_loss < best_val_loss:
        torch.save(
            {
                "model_state_dict": model.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
                "loss": best_val_loss,
            },
            save_path,
        )

def train(
    model,
    optimizer,
    loss_fn,
    train_loader,
    val_loader,
    epochs=20,
    device="cpu",
    scheduler=None,
    checkpoint_path=None,
    early_stopping=None,
):

    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []
    learning_rates = []


    best_val_loss = float("inf")
    early_stopping_counter = 0

    print("Model evaluation before start of training.")

    train_loss, train_accuracy = score(model, train_loader, loss_fn, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_accuracy)

    validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)
    val_losses.append(validation_loss)
    val_accuracies.append(validation_accuracy)

    for epoch in range(1, epochs + 1):
        print("\n")
        print(f"Starting epoch {epoch}/{epochs}")


        train_epoch(model, optimizer, loss_fn, train_loader, device)


        train_loss, train_accuracy = score(model, train_loader, loss_fn, device)
        train_losses.append(train_loss)
        train_accuracies.append(train_accuracy)


        validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)
        val_losses.append(validation_loss)
        val_accuracies.append(validation_accuracy)

        print(f"Epoch: {epoch}")
        print(f"Training loss: {train_loss:.4f}")
        print(f"Training accuracy: {train_accuracy*100:.4f}%")
        print(f"Validation loss: {validation_loss:.4f}")
        print(f"Validation accuracy: {validation_accuracy*100:.4f}%")


        lr = optimizer.param_groups[0]["lr"]
        learning_rates.append(lr)
        if scheduler:
            scheduler.step()


        if checkpoint_path:
            checkpointing(
                validation_loss, best_val_loss, model, optimizer, checkpoint_path
            )


        if early_stopping:
            early_stopping_counter, stop = early_stopping(
                validation_loss, best_val_loss, early_stopping_counter
            )
            if stop:
                print(f"Early stopping triggered after {epoch} epochs")
                break

        if validation_loss < best_val_loss:
            best_val_loss = validation_loss

    return (
        learning_rates,
        train_losses,
        val_losses,
        train_accuracies,
        val_accuracies,
        epoch,
    )

import os

epochs_to_train = 50


checkpoint_dir = os.path.dirname("model/LR_model.pth")
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)

train_results = train(
    model,
    optimizer,
    loss_fn,
    train_loader,
    val_loader,
    epochs=epochs_to_train,
    device=device,
    scheduler=scheduler,
    checkpoint_path="model/LR_model.pth",
    early_stopping=early_stopping,
)

(
    learning_rates,
    train_losses,
    valid_losses,
    train_accuracies,
    valid_accuracies,
    epochs,
) = train_results

eval_metrics_df = pd.DataFrame(
    {
        "Epoch": list(range(1, epochs + 1)),
        "Training Loss": train_losses[1:],
        "Validation Loss": valid_losses[1:],
        "Training Accuracy": train_accuracies[1:],
        "Validation Accuracy": valid_accuracies[1:],
        "Learning Rate": learning_rates,
    })

eval_metrics_df.head()

plt.plot(train_losses, label="Training Loss")
plt.plot(valid_losses, label="Validation Loss")
plt.title("Loss over epochs")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend();

plt.plot(train_accuracies, label="Training accuracies")


plt.plot(valid_accuracies, label="Validation accuracies")
plt.title("Accuracy over epochs")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend();

plt.figure(figsize=(10, 6))
plt.plot(range(1, epochs + 1), learning_rates, marker="o", label="Learning Rate")
plt.title("Learning Rate Schedule")
plt.xlabel("Epoch")
plt.ylabel("Learning Rate")
plt.show()

checkpoint = torch.load("model/LR_model.pth")

model.load_state_dict(checkpoint["model_state_dict"])
optimizer.load_state_dict(checkpoint["optimizer_state_dict"])

def predict(model, data_loader, device="cpu"):
    all_probs = torch.tensor([]).to(device)

    model.eval()
    with torch.no_grad():
        for inputs, targets in tqdm(data_loader, desc="Predicting", leave=False):
            inputs = inputs.to(device)
            output = model(inputs)
            probs = torch.nn.functional.softmax(output, dim=1)
            all_probs = torch.cat((all_probs, probs), dim=0)

    return all_probs

prob = predict(model, val_loader, device)
pred = torch.argmax(prob, dim=1)

from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
targets_val = torch.cat([labels for _, labels in tqdm(val_loader, desc="Get Labels")])

fig, ax = plt.subplots(figsize=(10, 6))

cm = confusion_matrix(targets_val.cpu(), pred.cpu())


classes = norm_dataset.classes


disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
disp.plot(cmap=plt.cm.Blues, xticks_rotation="vertical", ax=ax)

valid_classes = [classes[i] for i in pred]

print("Number of class predictions:", len(valid_classes))

from PIL import Image

sample_indices = random.sample(range(len(val_loader.dataset)), 12)


fig, axes = plt.subplots(4, 3, figsize=(20, 10))


for ax, idx in zip(axes.flatten(), sample_indices):
    image_path = val_loader.dataset.dataset.samples[val_loader.dataset.indices[idx]][0]
    img = Image.open(image_path)


    ax.imshow(img)
    ax.axis('off')


    predicted_class = valid_classes[idx]


    ax.set_title(f"Predicted: {predicted_class}", fontsize=14)

plt.tight_layout()

def undersample_dataset(dataset_dir, output_dir, target_count=None):

    classes_files = {}
    for class_name in os.listdir(dataset_dir):
        class_dir = os.path.join(dataset_dir, class_name)
        if os.path.isdir(class_dir):
            files = os.listdir(class_dir)
            classes_files[class_name] = files


    if target_count is None:
        target_count = min(len(files) for files in classes_files.values())


    if not os.path.exists(output_dir):
        os.makedirs(output_dir)


    for class_name, files in classes_files.items():
        print("Copying images for class", class_name)
        class_output_dir = os.path.join(output_dir, class_name)
        if not os.path.exists(class_output_dir):
            os.makedirs(class_output_dir)


        selected_files = random.sample(files, min(len(files), target_count))


        for file_name in tqdm(selected_files):
            src_path = os.path.join(dataset_dir, class_name, file_name)
            dst_path = os.path.join(class_output_dir, file_name)
            copy2(src_path, dst_path)

    print(f"Undersampling completed. Each class has up to {target_count} instances.")

output_dir = os.path.join("/content/drive/MyDrive/Colab Notebooks/DeepLeanrning/Agriculture_project/", "undersampled")
undersample_dataset(data_dir, output_dir)

undersample_dataset = datasets.ImageFolder(root=output_dir, transform=transform_norm)

undersample_dataset.classes

plt.figure(figsize=(15,8))
class_counts(undersample_dataset).plot(kind="bar");

undersample_dataloader = DataLoader(undersample_dataset, batch_size=32)

train_data, val_data = random_split(undersample_dataset, (0.8, 0.2))

print("Length of training dataset:", len(train_data))
print("Length of validation dataset:", len(val_data))

train_data_count = class_counts(train_data)
train_data_count.plot(kind="bar");

val_data_count = class_counts(val_data)
val_data_count.plot(kind="bar");

train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)
val_dataloader = DataLoader(val_data, batch_size=32, shuffle=False)

print(type(train_dataloader))
print(type(val_dataloader))

epochs_to_train = 50


checkpoint_dir = os.path.dirname("model/LR2_model.pth")
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)

train_results_u = train(
    model,
    optimizer,
    loss_fn,
    train_dataloader,
    val_dataloader,
    epochs=epochs_to_train,
    device=device,
    scheduler=scheduler,
    checkpoint_path="model/LR_model.pth",
    early_stopping=early_stopping,
)

(
    learning_rates_u,
    train_losses_u,
    valid_losses_u,
    train_accuracies_u,
    valid_accuracies_u,
    epochs,
) = train_results_u

eval_metrics_under_df = pd.DataFrame(
    {
        "Epoch": list(range(1, epochs + 1)),
        "Training Loss": train_losses_u[1:],
        "Validation Loss": valid_losses_u[1:],
        "Training Accuracy": train_accuracies_u[1:],
        "Validation Accuracy": valid_accuracies_u[1:],
        "Learning Rate": learning_rates_u,
    })

eval_metrics_under_df.head()

plt.plot(train_losses_u, label="Training Loss")
plt.plot(valid_losses_u, label="Validation Loss")
plt.title("Loss over epochs")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend();

plt.plot(train_accuracies_u, label="Training accuracies")

# Plot validation accuracies, use label="Validation Accuracy"
plt.plot(valid_accuracies_u, label="Validation accuracies")
plt.title("Accuracy over epochs")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend();

plt.figure(figsize=(10, 6))
plt.plot(range(1, epochs + 1), learning_rates_u, marker="o", label="Learning Rate")
plt.title("Learning Rate Schedule")
plt.xlabel("Epoch")
plt.ylabel("Learning Rate")
plt.show()

checkpoint_u = torch.load("model/LR_model.pth")

model.load_state_dict(checkpoint["model_state_dict"])
optimizer.load_state_dict(checkpoint["optimizer_state_dict"])

probabilities = predict(model, val_dataloader, device)

predictions = torch.argmax(probabilities, dim=1)

targets = []

for _, labels in tqdm(val_dataloader):
    targets.extend(labels.tolist())

from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix

fig, ax = plt.subplots(figsize=(10, 6))

cm = confusion_matrix(targets, predictions.cpu())

classes = undersample_dataset.classes

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
disp.plot(cmap=plt.cm.Blues, xticks_rotation="vertical", ax=ax)

val_classes = [classes[i] for i in predictions]

print("Number of class predictions:", len(val_classes))

from PIL import Image

sample_indices = random.sample(range(len(val_dataloader.dataset)), 24)


fig, axes = plt.subplots(4, 3, figsize=(20, 10))


for ax, idx in zip(axes.flatten(), sample_indices):
    image_path = val_dataloader.dataset.dataset.samples[val_dataloader.dataset.indices[idx]][0]
    img = Image.open(image_path)


    ax.imshow(img)
    ax.axis('off')


    predicted_class = val_classes[idx]


    ax.set_title(f"Predicted: {predicted_class}", fontsize=14)

plt.tight_layout()

